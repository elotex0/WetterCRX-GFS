name: Fetch GFS GRIB2 and Generate PNGs

on:
  workflow_dispatch:

jobs:
  # -------------------------------------------------------
  # 1Ô∏è‚É£ Fetch all GRIB2 data
  # -------------------------------------------------------
  fetch_and_generate:
    runs-on: ubuntu-latest
    outputs:
      run: ${{ steps.set_run_date.outputs.run }}
      date: ${{ steps.set_run_date.outputs.date }}

    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GFS_PAT }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Cache Python packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Set RUN and DATE
        id: set_run_date
        run: |
          HOUR=$(date -u +%H)
          case $HOUR in
            05|06|07) RUN=00 ;;
            11|12|13) RUN=06 ;;
            17|18|19) RUN=12 ;;
            23|00|01) RUN=18 ;;
          esac
          DATE=$(date -u +%Y%m%d)
          echo "RUN=$RUN" >> $GITHUB_ENV
          echo "DATE=$DATE" >> $GITHUB_ENV
          echo "run=$RUN" >> $GITHUB_OUTPUT
          echo "date=$DATE" >> $GITHUB_OUTPUT

      - name: Download t2m GRIB2 files
        run: |
          mkdir -p data/t2m
          cd data/t2m
          echo "üîπ Lade T2M-Dateien f√ºr DATE=${{ env.DATE }}, RUN=${{ env.RUN }}"
      
          export DATE=${{ env.DATE }}
          export RUN=${{ env.RUN }}
      
          echo "üîπ Lade Dateien 0‚Äì119..."
          seq 0 119 | xargs -n 1 -P 2 -I{} bash -c '
            i_padded=$(printf "%03d" {})
            URL="https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?dir=%2Fgfs.${DATE}%2F${RUN}%2Fatmos&file=gfs.t${RUN}z.pgrb2.0p25.f${i_padded}&var_TMP=on&lev_2_m_above_ground=on"
            echo "‚Üí $URL"
            for attempt in {1..5}; do
              wget -q --timeout=60 --max-redirect=20 -O t2m_${i_padded}.grib2 "$URL" && break
              echo "‚ö†Ô∏è Versuch $attempt f√ºr f${i_padded} fehlgeschlagen, warte 15 s..."
              sleep 15
            done
            [ -s t2m_${i_padded}.grib2 ] || echo "‚ùå Datei f${i_padded} nicht verf√ºgbar ‚Äì √ºberspringe."
          '
      
          echo "üîπ Lade Dateien 120‚Äì384..."
          seq 120 3 384 | xargs -n 1 -P 2 -I{} bash -c '
            i_padded=$(printf "%03d" {})
            URL="https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?dir=%2Fgfs.${DATE}%2F${RUN}%2Fatmos&file=gfs.t${RUN}z.pgrb2.0p25.f${i_padded}&var_TMP=on&lev_2_m_above_ground=on"
            echo "‚Üí $URL"
            for attempt in {1..5}; do
              wget -q --timeout=60 --max-redirect=20 -O t2m_${i_padded}.grib2 "$URL" && break
              echo "‚ö†Ô∏è Versuch $attempt f√ºr f${i_padded} fehlgeschlagen, warte 15 s..."
              sleep 15
            done
            [ -s t2m_${i_padded}.grib2 ] || echo "‚ùå Datei f${i_padded} nicht verf√ºgbar ‚Äì √ºberspringe."
          '


      - name: Download WIND GRIB2 files
        run: |
          mkdir -p data/wind
          cd data/wind
          echo "üîπ Lade WIND-Dateien f√ºr DATE=${{ env.DATE }}, RUN=${{ env.RUN }}"
      
          export DATE=${{ env.DATE }}
          export RUN=${{ env.RUN }}
      
          echo "üîπ Lade Dateien 0‚Äì119..."
          seq 0 119 | xargs -n 1 -P 2 -I{} bash -c '
            i_padded=$(printf "%03d" {})
            URL="https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?dir=%2Fgfs.${DATE}%2F${RUN}%2Fatmos&file=gfs.t${RUN}z.pgrb2.0p25.f${i_padded}&var_GUST=on&lev_surface=on"
            echo "‚Üí $URL"
            for attempt in {1..5}; do
              wget -q --timeout=60 --max-redirect=20 -O wind_${i_padded}.grib2 "$URL" && break
              echo "‚ö†Ô∏è Versuch $attempt f√ºr f${i_padded} fehlgeschlagen, warte 15 s..."
              sleep 15
            done
            [ -s wind_${i_padded}.grib2 ] || echo "‚ùå Datei f${i_padded} nicht verf√ºgbar ‚Äì √ºberspringe."
          '
      
          echo "üîπ Lade Dateien 120‚Äì384..."
          seq 120 3 384 | xargs -n 1 -P 2 -I{} bash -c '
            i_padded=$(printf "%03d" {})
            URL="https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?dir=%2Fgfs.${DATE}%2F${RUN}%2Fatmos&file=gfs.t${RUN}z.pgrb2.0p25.f${i_padded}&var_GUST=on&lev_surface=on"
            echo "‚Üí $URL"
            for attempt in {1..5}; do
              wget -q --timeout=60 --max-redirect=20 -O wind_${i_padded}.grib2 "$URL" && break
              echo "‚ö†Ô∏è Versuch $attempt f√ºr f${i_padded} fehlgeschlagen, warte 15 s..."
              sleep 15
            done
            [ -s wind_${i_padded}.grib2 ] || echo "‚ùå Datei f${i_padded} nicht verf√ºgbar ‚Äì √ºberspringe."
          '

      - name: Download PMSL GRIB2 files
        run: |
          mkdir -p data/pmsl
          cd data/pmsl
      
          echo "üîπ Lade PMSL-Dateien f√ºr DATE=${{ env.DATE }}, RUN=${{ env.RUN }}"
      
          # Variablen exportieren, damit sie in der Subshell sichtbar sind
          export DATE=${{ env.DATE }}
          export RUN=${{ env.RUN }}
      
          echo "üîπ Lade Dateien 0‚Äì119..."
          seq 0 119 | xargs -n 1 -P 2 -I{} bash -c '
            i_padded=$(printf "%03d" {})
            URL="https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?dir=%2Fgfs.${DATE}%2F${RUN}%2Fatmos&file=gfs.t${RUN}z.pgrb2.0p25.f${i_padded}&var_PRMSL=on&lev_mean_sea_level=on"
            echo "‚Üí $URL"
            for attempt in {1..5}; do
              wget -q --timeout=60 --max-redirect=20 -O pmsl_${i_padded}.grib2 "$URL" && break
              echo "‚ö†Ô∏è Versuch $attempt f√ºr f${i_padded} fehlgeschlagen, warte 15 s..."
              sleep 15
            done
            [ -s pmsl_${i_padded}.grib2 ] || echo "‚ùå Datei f${i_padded} nicht verf√ºgbar ‚Äì √ºberspringe."
          '
      
          echo "üîπ Lade Dateien 120‚Äì384..."
          seq 120 3 384 | xargs -n 1 -P 2 -I{} bash -c '
            i_padded=$(printf "%03d" {})
            URL="https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?dir=%2Fgfs.${DATE}%2F${RUN}%2Fatmos&file=gfs.t${RUN}z.pgrb2.0p25.f${i_padded}&var_PRMSL=on&lev_mean_sea_level=on"
            echo "‚Üí $URL"
            for attempt in {1..5}; do
              wget -q --timeout=60 --max-redirect=20 -O pmsl_${i_padded}.grib2 "$URL" && break
              echo "‚ö†Ô∏è Versuch $attempt f√ºr f${i_padded} fehlgeschlagen, warte 15 s..."
              sleep 15
            done
            [ -s pmsl_${i_padded}.grib2 ] || echo "‚ùå Datei f${i_padded} nicht verf√ºgbar ‚Äì √ºberspringe."
          '
      

      - name: Upload GRIB2 as artifact
        uses: actions/upload-artifact@v4
        with:
          name: grib2
          path: data/

      - name: Delete GRIB2 files (local cleanup)
        run: rm -rf data/

  # -------------------------------------------------------
  # 2Ô∏è‚É£ Generate PNGs in parallel (matrix)
  # -------------------------------------------------------
  generate_pngs:
    runs-on: ubuntu-latest
    needs: fetch_and_generate
    strategy:
      matrix:
        variable: [t2m, wind, pmsl, pmsl_eu]
      max-parallel: 4
      
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download GRIB2 artifact
        uses: actions/download-artifact@v4
        with:
          name: grib2
          path: data/

      - name: Generate PNGs for ${{ matrix.variable }}
        run: |
          mkdir -p iconeu/${{ matrix.variable }}
          input_dir="data/${{ matrix.variable }}"
          if [ "${{ matrix.variable }}" = "pmsl_eu" ]; then
            input_dir="data/pmsl"
          fi
          python scripts/generate_pngs.py \
            "$input_dir" \
            "gfs/${{ matrix.variable }}" \
            "${{ matrix.variable }}"


      - name: Upload PNGs artifact
        uses: actions/upload-artifact@v4
        with:
          name: gfs-${{ matrix.variable }}
          path: gfs/${{ matrix.variable }}

  # -------------------------------------------------------
  # 3Ô∏è‚É£ Merge PNGs + Deploy to R2
  # -------------------------------------------------------
  deploy_to_r2:
    runs-on: ubuntu-latest
    needs: [fetch_and_generate, generate_pngs]
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3

      - name: Download all PNG artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: gfs-*
          path: gfs_raw

      - name: Merge PNG folders into one structure
        run: |
          mkdir -p gfs/${{ needs.fetch_and_generate.outputs.run }}
          for d in gfs_raw/*; do
            if [ -d "$d" ]; then
              varname=$(basename "$d" | sed 's/^gfs-//')  # entfernt "gfs-" Prefix
              mkdir -p gfs/${{ needs.fetch_and_generate.outputs.run }}/"$varname"
              cp -r "$d"/* gfs/${{ needs.fetch_and_generate.outputs.run }}/"$varname"/ || true
            fi
          done


          echo "Merged structure:"
          ls -R gfs/${{ needs.fetch_and_generate.outputs.run }}

      - name: Generate Metadata
        run: |
          python scripts/generate_metadata.py \
            gfs/${{ needs.fetch_and_generate.outputs.run }} \
            ${{ needs.fetch_and_generate.outputs.run }} \
            ${{ needs.fetch_and_generate.outputs.date }}

      - name: Clean old runs on R2 except current
        run: |
          for run_folder in $(aws s3 ls s3://${{ secrets.R2_BUCKET }}/gfs/ \
            --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com | awk '{print $2}' | sed 's#/##'); do
            if [ "$run_folder" != "${{ needs.fetch_and_generate.outputs.run }}/" ]; then
              aws s3 rm s3://${{ secrets.R2_BUCKET }}/gfs/$run_folder --recursive \
                --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
            fi
          done
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}

      - name: Upload current run and metadata.json to R2
        run: |
          aws s3 sync ./gfs/${{ needs.fetch_and_generate.outputs.run }}/ \
            s3://${{ secrets.R2_BUCKET }}/gfs/${{ needs.fetch_and_generate.outputs.run }}/ \
            --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com

          aws s3 cp ./gfs/metadata.json \
            s3://${{ secrets.R2_BUCKET }}/gfs/metadata.json \
            --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
